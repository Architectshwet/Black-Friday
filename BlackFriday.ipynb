{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Architect_shwet\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
       "0  1000001  P00069042      F  0-17          10             A   \n",
       "1  1000001  P00248942      F  0-17          10             A   \n",
       "2  1000001  P00087842      F  0-17          10             A   \n",
       "3  1000001  P00085442      F  0-17          10             A   \n",
       "4  1000002  P00285442      M   55+          16             C   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               0                   3   \n",
       "1                          2               0                   1   \n",
       "2                          2               0                  12   \n",
       "3                          2               0                  12   \n",
       "4                         4+               0                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 NaN                 NaN      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2                 NaN                 NaN      1422  \n",
       "3                14.0                 NaN      1057  \n",
       "4                 NaN                 NaN      7969  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating the test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(783667, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(233599, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [train, test]\n",
    "input = pd.concat(frames)\n",
    "\n",
    "print (input.shape)\n",
    "input.head()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input.fillna(999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Purchase</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>User_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-17</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>8370.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-17</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>15200.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-17</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0-17</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>1057.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55+</td>\n",
       "      <td>C</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>999.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>7969.0</td>\n",
       "      <td>4+</td>\n",
       "      <td>1000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age City_Category Gender  Marital_Status  Occupation  Product_Category_1  \\\n",
       "0  0-17             A      F               0          10                   3   \n",
       "1  0-17             A      F               0          10                   1   \n",
       "2  0-17             A      F               0          10                  12   \n",
       "3  0-17             A      F               0          10                  12   \n",
       "4   55+             C      M               0          16                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3 Product_ID  Purchase  \\\n",
       "0               999.0               999.0  P00069042    8370.0   \n",
       "1                 6.0                14.0  P00248942   15200.0   \n",
       "2               999.0               999.0  P00087842    1422.0   \n",
       "3                14.0               999.0  P00085442    1057.0   \n",
       "4               999.0               999.0  P00285442    7969.0   \n",
       "\n",
       "  Stay_In_Current_City_Years  User_ID  \n",
       "0                          2  1000001  \n",
       "1                          2  1000001  \n",
       "2                          2  1000001  \n",
       "3                          2  1000001  \n",
       "4                         4+  1000002  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = input.Purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input.drop([\"Purchase\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                           object\n",
       "City_Category                 object\n",
       "Gender                        object\n",
       "Marital_Status                object\n",
       "Occupation                    object\n",
       "Product_Category_1            object\n",
       "Product_Category_2            object\n",
       "Product_Category_3            object\n",
       "Product_ID                    object\n",
       "Stay_In_Current_City_Years    object\n",
       "User_ID                       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert all the columns to string \n",
    "input = input.applymap(str)\n",
    "input.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Have a copy of the pandas dataframe. Will be useful later on\n",
    "input_pd = input.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert categorical to numeric using LabelEncoder\n",
    "\n",
    "input = np.array(input)\n",
    "\n",
    "for i in range(input.shape[1]):\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(input[:,i]))\n",
    "    input[:, i] = lbl.transform(input[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = input.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission=pd.read_csv('Sample_Submission_Tm9Lura.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the xgboost model.\n",
    "i) Parameter \"min_child_weight\" used to control over-fitting. Higher values prevent a model from learning relations which might be highly specific to the particular sample selected for a tree. Defines the minimum sum of weights of all observations required in a field.\n",
    "ii) Parameter \"subsample\" denotes the fraction of observations to be randomly samples for each tree. Lowe values make the algorithm more conservative and prevents overfitting but too small might leads to underfitting. Typical values 0.5-1.\n",
    "iii) Parameter \"colsample_bytree\" denotes the fraction of columns to be randomly samples for each tree.\n",
    "iv) Parameter \"silent\" is 1 so that no running messages will be printed.\n",
    "v) Parameter \"nthread\" is used for parallel processing and number of cores in the system to be printed.\n",
    "vi) Parameter \"objective\" is reg:linear here.\n",
    "vii) Parameter \"eta\" is analogous to learning rate and makes the model more robust by shrinking weight at each step.\n",
    "viii) Parameter \"eval_metric\" is rmse here.\n",
    "ix) Parameter \"seed\" can be used for generating reproductible results and also for parameter tuning.\n",
    "x) Parameter \"max_depth\" used to control over-fitting as higher depth will allow model to learn relations very specific to a particular sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"min_child_weight\"] = 10\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"scale_pos_weight\"] = 0.8\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 6\n",
    "params[\"nthread\"] = 6\n",
    "#params[\"gamma\"] = 1\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"base_score\"] = 1800\n",
    "params[\"eval_metric\"] = \"rmse\"\n",
    "params[\"seed\"] = 0\n",
    "\n",
    "plst = list(params.items())\n",
    "num_rounds = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(input[:train.shape[0],:], label=target[:train.shape[0]])\n",
    "watchlist = [(xgtrain, 'train')]\n",
    "model_1_xgboost = xgb.train(plst, xgtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1_predict = model_1_xgboost.predict(xgb.DMatrix(input[train.shape[0]:,:]))\n",
    "model_1_predict[model_1_predict<0] = 25\n",
    "submission.Purchase = model_1_predict\n",
    "submission.User_ID=test.User_ID\n",
    "submission.Product_ID=test.Product_ID\n",
    "submission.to_csv(\"sub1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000004</td>\n",
       "      <td>P00128942</td>\n",
       "      <td>15122.963867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000009</td>\n",
       "      <td>P00113442</td>\n",
       "      <td>10431.894531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000010</td>\n",
       "      <td>P00288442</td>\n",
       "      <td>6955.890137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000010</td>\n",
       "      <td>P00145342</td>\n",
       "      <td>3446.657227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000011</td>\n",
       "      <td>P00053842</td>\n",
       "      <td>968.134460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID      Purchase\n",
       "0  1000004  P00128942  15122.963867\n",
       "1  1000009  P00113442  10431.894531\n",
       "2  1000010  P00288442   6955.890137\n",
       "3  1000010  P00145342   3446.657227\n",
       "4  1000011  P00053842    968.134460"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550068"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data for stacking model\n",
    "Split dataset into two. First level models to create meta features to feed into a second level model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_stage_rows = np.random.randint(train.shape[0], size = np.int(train.shape[0]/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_np   = input[:train.shape[0], :]\n",
    "target_np  = target[:train.shape[0]]\n",
    "train_fs   = train_np[first_stage_rows, :]\n",
    "target_fs  = target_np[first_stage_rows]\n",
    "train_ss   = train_np[-first_stage_rows, :]\n",
    "target_ss  = target_np[-first_stage_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275034, 11) (275034,) (275034, 11) (275034,)\n"
     ]
    }
   ],
   "source": [
    "print (train_fs.shape, target_fs.shape, train_ss.shape, target_ss.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Four different models of xgboost with altering max_depth and num_rounds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(train_fs, label=target_fs)\n",
    "watchlist = [(xgtrain, 'train')]\n",
    "\n",
    "# Model 1: 6/3000\n",
    "\n",
    "params = {}\n",
    "params[\"min_child_weight\"] = 10\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"scale_pos_weight\"] = 0.8\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 6\n",
    "params[\"nthread\"] = 6\n",
    "#params[\"gamma\"] = 1\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"base_score\"] = 1800\n",
    "params[\"eval_metric\"] = \"rmse\"\n",
    "params[\"seed\"] = 0\n",
    "\n",
    "plst = list(params.items())\n",
    "num_rounds = 3000\n",
    "\n",
    "model_1 = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "# Model 2: 8/1420\n",
    "\n",
    "params = {}\n",
    "params[\"min_child_weight\"] = 10\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"scale_pos_weight\"] = 0.8\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 8\n",
    "params[\"nthread\"] = 6\n",
    "#params[\"gamma\"] = 1\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"base_score\"] = 1800\n",
    "params[\"eval_metric\"] = \"rmse\"\n",
    "params[\"seed\"] = 0\n",
    "\n",
    "plst = list(params.items())\n",
    "num_rounds = 1420\n",
    "\n",
    "model_2 = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "# Model 3: 10/1200\n",
    "\n",
    "params = {}\n",
    "params[\"min_child_weight\"] = 10\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"scale_pos_weight\"] = 0.8\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 10\n",
    "params[\"nthread\"] = 6\n",
    "#params[\"gamma\"] = 1\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"base_score\"] = 1800\n",
    "params[\"eval_metric\"] = \"rmse\"\n",
    "params[\"seed\"] = 0\n",
    "\n",
    "plst = list(params.items())\n",
    "num_rounds = 1200\n",
    "\n",
    "model_3 = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "# Model 4: 12/800\n",
    "\n",
    "params = {}\n",
    "params[\"min_child_weight\"] = 10\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"scale_pos_weight\"] = 0.8\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 12\n",
    "params[\"nthread\"] = 6\n",
    "#params[\"gamma\"] = 1\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"base_score\"] = 1800\n",
    "params[\"eval_metric\"] = \"rmse\"\n",
    "params[\"seed\"] = 0\n",
    "\n",
    "plst = list(params.items())\n",
    "num_rounds = 800\n",
    "\n",
    "model_4 = xgb.train(plst, xgtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three different models of ExtraTreesRegressor with altering n_estimators and max_Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This set of models will be ExtraTrees\n",
    "\n",
    "# Model 5: 8/1450\n",
    "\n",
    "model_5 = ExtraTreesRegressor(n_estimators=1450, \n",
    "                              max_depth=8,\n",
    "                              min_samples_split=10, \n",
    "                              min_samples_leaf=10, \n",
    "                              oob_score=True, \n",
    "                              n_jobs=6, \n",
    "                              random_state=123, \n",
    "                              verbose=1, \n",
    "                              bootstrap=True)\n",
    "model_5.fit(train_fs, target_fs)\n",
    "\n",
    "# Model 6: 6/3000\n",
    "\n",
    "model_6 = ExtraTreesRegressor(n_estimators=3000, \n",
    "                              max_depth=6,\n",
    "                              min_samples_split=10, \n",
    "                              min_samples_leaf=10, \n",
    "                              oob_score=True, \n",
    "                              n_jobs=6, \n",
    "                              random_state=123, \n",
    "                              verbose=1, \n",
    "                              bootstrap=True)\n",
    "model_6.fit(train_fs, target_fs)\n",
    "\n",
    "# Model 7: 12/800\n",
    "\n",
    "model_7 = ExtraTreesRegressor(n_estimators=800, \n",
    "                              max_depth=12,\n",
    "                              min_samples_split=10, \n",
    "                              min_samples_leaf=10, \n",
    "                              oob_score=True, \n",
    "                              n_jobs=6, \n",
    "                              random_state=123, \n",
    "                              verbose=1, \n",
    "                              bootstrap=True)\n",
    "model_7.fit(train_fs, target_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarly, three different models of RandomForest with altering n_estimators and max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This set of models will be RandomForest\n",
    "\n",
    "# Model 8: 6/3000\n",
    "model_8 = RandomForestRegressor(n_estimators=3000, max_depth=6, oob_score=True, n_jobs=6, random_state=123, min_samples_split=10, min_samples_leaf=10)\n",
    "model_8.fit(train_fs, target_fs)\n",
    "\n",
    "# Model 9: 8/1500\n",
    "model_9 = RandomForestRegressor(n_estimators=1500, max_depth=8, oob_score=True, n_jobs=6, random_state=123, min_samples_split=10, min_samples_leaf=10)\n",
    "model_9.fit(train_fs, target_fs)\n",
    "\n",
    "# Model 10: 12/800\n",
    "model_10 = RandomForestRegressor(n_estimators=800, max_depth=12, oob_score=True, n_jobs=6, random_state=123, min_samples_split=10, min_samples_leaf=10)\n",
    "model_10.fit(train_fs, target_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting on the next level of training dataset with all the 10 models separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1_predict = model_1.predict(xgb.DMatrix(train_ss))\n",
    "model_2_predict = model_2.predict(xgb.DMatrix(train_ss))\n",
    "model_3_predict = model_3.predict(xgb.DMatrix(train_ss))\n",
    "model_4_predict = model_4.predict(xgb.DMatrix(train_ss))\n",
    "model_5_predict = model_5.predict(train_ss)\n",
    "model_6_predict = model_6.predict(train_ss)\n",
    "model_7_predict = model_7.predict(train_ss)\n",
    "model_8_predict = model_8.predict(train_ss)\n",
    "model_9_predict = model_9.predict(train_ss)\n",
    "model_10_predict = model_10.predict(train_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenating all the models ( stacking them ) with numpy vstack function and concatenate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ss_w_meta = np.concatenate((train_ss, np.vstack((model_1_predict, model_2_predict, model_3_predict, \n",
    "                                                       model_4_predict, model_5_predict,\n",
    "              model_6_predict, model_7_predict, model_8_predict, model_9_predict, model_10_predict)).T), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the new and final xgboost model on the concatenated stack training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[\"min_child_weight\"] = 10\n",
    "params[\"subsample\"] = 0.7\n",
    "params[\"colsample_bytree\"] = 0.7\n",
    "params[\"scale_pos_weight\"] = 0.8\n",
    "params[\"silent\"] = 1\n",
    "params[\"max_depth\"] = 8\n",
    "params[\"nthread\"] = 6\n",
    "#params[\"gamma\"] = 1\n",
    "params[\"objective\"] = \"reg:linear\"\n",
    "params[\"eta\"] = 0.1\n",
    "params[\"base_score\"] = 1800\n",
    "params[\"eval_metric\"] = \"rmse\"\n",
    "params[\"seed\"] = 0\n",
    "\n",
    "plst = list(params.items())\n",
    "num_rounds = 1400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(train_ss_w_meta, label=target_ss)\n",
    "watchlist = [(xgtrain, 'train')]\n",
    "model_ss_xgboost = xgb.train(plst, xgtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the 10 models on the test data in the similar manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1_predict = model_1.predict(xgb.DMatrix(input[train.shape[0]:, :]))\n",
    "model_2_predict = model_2.predict(xgb.DMatrix(input[train.shape[0]:, :]))\n",
    "model_3_predict = model_3.predict(xgb.DMatrix(input[train.shape[0]:, :]))\n",
    "model_4_predict = model_4.predict(xgb.DMatrix(input[train.shape[0]:, :]))\n",
    "model_5_predict = model_5.predict(input[train.shape[0]:, :])\n",
    "model_6_predict = model_6.predict(input[train.shape[0]:, :])\n",
    "model_7_predict = model_7.predict(input[train.shape[0]:, :])\n",
    "model_8_predict = model_8.predict(input[train.shape[0]:, :])\n",
    "model_9_predict = model_9.predict(input[train.shape[0]:, :])\n",
    "model_10_predict = model_10.predict(input[train.shape[0]:, :])\n",
    "\n",
    "test_ss_w_meta = np.concatenate((input[train.shape[0]:, :], np.vstack((model_1_predict, model_2_predict, model_3_predict, \n",
    "                                                       model_4_predict, model_5_predict,\n",
    "              model_6_predict, model_7_predict, model_8_predict, model_9_predict, model_10_predict)).T), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The last xgboost model which was trained on the the concatenated training data is now predicted on the concatenated stacked test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model_ss_predict = model_ss_xgboost.predict(xgb.DMatrix(test_ss_w_meta))\n",
    "submission.Purchase = model_ss_predict\n",
    "submission.to_csv(\"sub2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
